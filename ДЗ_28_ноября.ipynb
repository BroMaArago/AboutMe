{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3NLDnKo7imRbURofj2r4/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BroMaArago/AboutMe/blob/main/%D0%94%D0%97_28_%D0%BD%D0%BE%D1%8F%D0%B1%D1%80%D1%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suwlhiZyfrYj"
      },
      "outputs": [],
      "source": [
        "#1 задание\n",
        "import nltk\n",
        "nltk.download('opinion_lexicon')\n",
        "\n",
        "\n",
        "from nltk.corpus import opinion_lexicon\n",
        "opinion_lexicon.words()\n",
        "\n",
        "\n",
        "def tone(text):\n",
        "    pos = set(opinion_lexicon.positive())\n",
        "    neg = set(opinion_lexicon.negative())\n",
        "    tokens = text.lower().split()\n",
        "    score = 0\n",
        "    for word in tokens:\n",
        "        if word in pos:\n",
        "            score += 1\n",
        "        if word in neg:\n",
        "            score -= 1\n",
        "    if score > 0:\n",
        "        return 'positive'\n",
        "    if score < 0:\n",
        "        return 'negative'\n",
        "    if score == 0:\n",
        "        return 'neutral'\n",
        "\n",
        "\n",
        "text = str(input())\n",
        "print(tone(text))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 задание\n",
        "def jac(x, y):\n",
        "    x = set(x.split())\n",
        "    y = set(y.split())\n",
        "    shared = x.intersection(y)\n",
        "    union = len(x) + len(y) - len(shared)\n",
        "    sim = len(shared) / union\n",
        "    return round(sim, 2)\n",
        "\n",
        "\n",
        "s1 = input()\n",
        "s2 = input()\n",
        "print(jac(s1, s2))"
      ],
      "metadata": {
        "id": "3GZSMAouga9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3 задание\n",
        "import pprint\n",
        "from gensim import corpora\n",
        "\n",
        "\n",
        "review_corpus = [\"Eighty percent of success is showing up.\",\n",
        "               'If at first you don’t succeed, try, try again.',\n",
        "               'You must be the change you wish to see in the world']\n",
        "\n",
        "\n",
        "def unique_tokens(text):\n",
        "\n",
        "  # Создайтей набор часто встречающихся слов\n",
        "\n",
        "  stoplist = set('x'.split(' '))\n",
        "\n",
        "  # Каждый документ строчными буквами, разделите его пробелами и отфильтруйте стоп-слова.\n",
        "\n",
        "  texts = [[word for word in document.lower().split() if word not in stoplist]\n",
        "           for document in text]\n",
        "\n",
        "  # Подсчитайте частоты слов\n",
        "\n",
        "  from collections import defaultdict\n",
        "  frequency = defaultdict(int)\n",
        "  for text in texts:\n",
        "      for token in text:\n",
        "          frequency[token] += 1\n",
        "\n",
        "\n",
        "\n",
        "  processed_corpus = [[token for token in text if frequency[token] == 1] for text in texts]\n",
        "  pprint.pprint(processed_corpus)\n",
        "\n",
        "  dictionary = corpora.Dictionary(processed_corpus)\n",
        "  return(dictionary)"
      ],
      "metadata": {
        "id": "1kjswXnOg7IP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}